<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<style>
h1,
h2,
h3,
h4,
h5,
h6,
p,
blockquote {
    margin: 0;
    padding: 0;
}
body {
    font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", Arial, sans-serif;
    font-size: 13px;
    line-height: 18px;
    color: #737373;
    background-color: white;
    margin: 10px 13px 10px 13px;
}
table {
	margin: 10px 0 15px 0;
	border-collapse: collapse;
}
td,th {	
	border: 1px solid #ddd;
	padding: 3px 10px;
}
th {
	padding: 5px 10px;	
}

a {
    color: #0069d6;
}
a:hover {
    color: #0050a3;
    text-decoration: none;
}
a img {
    border: none;
}
p {
    margin-bottom: 9px;
}
h1,
h2,
h3,
h4,
h5,
h6 {
    color: #404040;
    line-height: 36px;
}
h1 {
    margin-bottom: 18px;
    font-size: 30px;
}
h2 {
    font-size: 24px;
}
h3 {
    font-size: 18px;
}
h4 {
    font-size: 16px;
}
h5 {
    font-size: 14px;
}
h6 {
    font-size: 13px;
}
hr {
    margin: 0 0 19px;
    border: 0;
    border-bottom: 1px solid #ccc;
}
blockquote {
    padding: 13px 13px 21px 15px;
    margin-bottom: 18px;
    font-family:georgia,serif;
    font-style: italic;
}
blockquote:before {
    content:"\201C";
    font-size:40px;
    margin-left:-10px;
    font-family:georgia,serif;
    color:#eee;
}
blockquote p {
    font-size: 14px;
    font-weight: 300;
    line-height: 18px;
    margin-bottom: 0;
    font-style: italic;
}
code, pre {
    font-family: Monaco, Andale Mono, Courier New, monospace;
}
code {
    background-color: #fee9cc;
    color: rgba(0, 0, 0, 0.75);
    padding: 1px 3px;
    font-size: 12px;
    -webkit-border-radius: 3px;
    -moz-border-radius: 3px;
    border-radius: 3px;
}
pre {
    display: block;
    padding: 14px;
    margin: 0 0 18px;
    line-height: 16px;
    font-size: 11px;
    border: 1px solid #d9d9d9;
    white-space: pre-wrap;
    word-wrap: break-word;
}
pre code {
    background-color: #fff;
    color:#737373;
    font-size: 11px;
    padding: 0;
}
sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}
* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:10px auto;
    }
}
@media print {
	body,code,pre code,h1,h2,h3,h4,h5,h6 {
		color: black;
	}
	table, pre {
		page-break-inside: avoid;
	}
}
</style>
<title>This is the GPU based ANUGA 
===========================



Documentation
-------------

Documentation is under doc directory, and the html</title>
<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[['$$$','$$$']]}});</script><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<h1>This is the GPU based ANUGA </h1>

<h2>Documentation</h2>

<p>Documentation is under doc directory, and the html version generated by <strong>Sphinx</strong> under the directory <em>doc/sphinx/build/html/</em></p>

<h2>Install Guide</h2>

<ol>
<li>Original <a href="anuga.anu.edu.au">ANUGA</a> is required</li>
<li>For CUDA version, <a href="documen.tician.de/pycuda">PyCUDA</a> is required</li>
<li>For OpenHMPP version, current implementation is based on the <a href="www.caps-entreprise.com">CAPS OpenHMPP Compiler</a>

<ul>
<li>When compiling the code with <strong>Makefile</strong>, the NVIDIA device architecture and compute capability need to be specified

<ul>
<li>For example, GTX480 with 2.0 compute capability </br>
<code>HMPP_FLAGS13 = -e --nvcc-options -Xptxas=-v,-arch=sm_20 -c --force</code></li>
<li>For GTX680 with 3.0 compute capability </br>
<code>HMPP_FLAGS13 = -e --nvcc-options -Xptxas=-v,-arch=sm_30 -c --force</code></li>
</ul>
</li>
<li>Also the path for <strong>python</strong>, <strong>numpy</strong>, and <strong>ANUGA/utilities</strong> packages need to be specified</li>
<li>Defining the macro <strong>USING_MIRROR_DATA</strong> in <strong>hmpp_fun.h</strong> </br>
<code>#define USING_MIRROR_DATA</code>
</br>will enable the advanced version, which uses OpenHMPP Mirrored Data technology so that data transmission costs can be effectively cut down, otherwise basic version is enabled.</li>
</ul>
</li>
</ol>


<h2>Environment Vars</h2>

<p>Please add following vars to you <strong>.bashrc</strong> or <strong>.bash_profile</strong> file</p>

<pre><code>export ANUGA_CUDA=/where_the_anuga-cuda/src

export $PYTHONPATH=$PYTHONPATH:$ANUGA_CUDA
</code></pre>

<h2>Basic Code Structure</h2>

<p><img src="docs/codeStructure.pdf" title="anuga-cuda code structure" alt="Code Structure" /></p>

<ul>
<li><strong>README</strong> (What you are reading)</li>
<li><strong>docs/</strong> Documentation directory

<ul>
<li><strong>codeStructure.pdf</strong> The diagram above</li>
<li><strong>Evolve workflow.pdf</strong> The overall workflow of the evolve procedure. This includes all the function dependency and function interfaces, which is helpful to understand the evolve procedure of ANUGA</li>
<li><strong>device_spe/</strong> Some device specifications of our working station</li>
<li><strong>profiling/</strong> Profiling results

<ul>
<li><strong>CUDA/</strong> All the profiling results on CUDA implementation</li>
</ul>
</li>
<li><strong>sphinx/</strong> The <a href="http://sphinx-doc.org/">Sphinx</a> generated documentation

<ul>
<li><strong>source/</strong> The source files for Sphinx based documents</li>
<li><strong>build/</strong> The generated documents

<ul>
<li><strong>html/</strong> HTML version documentation</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>src/</strong> Source code directory

<ul>
<li><strong>anuga_cuda/</strong> The CUDA implementation

<ul>
<li><strong>config.py</strong> Detail configuration for the CUDA implementation, including the path for all the kernel functions, optimal CUDA thread block configuration, etc.</li>
<li><strong>gpu_domain_advanced.py</strong> Python Class for CUDA implementation in advanced version</li>
<li><strong>gpu_domain_basic.py</strong> Python Class for CUDA implementation in basic version</li>
</ul>
</li>
<li><strong>anuga_HMPP/</strong> The OpenHMPP implementation

<ul>
<li><strong>Makefile</strong> The Makefile</li>
<li><strong>hmpp_dimain.py</strong> Python Class for OpenHMPP implementation</li>
<li><strong>hmpp_python_glue.c</strong> The Python/C API to set up communication between Python ANUGA and OpenHMPP.</li>
<li><strong>sw_domain.h</strong> The C Struct type <strong>domain</strong> used in C implementation to access mesh information generated in Python ANUGA</li>
<li><strong>sw_domain_fun.h</strong> Connect C Struct type <strong>domain</strong> to all mesh information</li>
<li><strong>hmpp_fun.h</strong> All function declarations.</li>
<li><strong>evolve.c</strong> The evolve procedure</li>
</ul>
</li>
<li><strong>scripts/</strong> Some useful bash script</li>
<li><strong>utilities/</strong> Utilities for sorting mesh information, checking results, etc.</li>
</ul>
</li>
<li><strong>test/</strong> Testing cases

<ul>
<li><strong>CUDA/</strong> Testing cases for CUDA implementation

<ul>
<li><strong>merimbula/</strong> Merimbula testing case directory

<ul>
<li><strong>merimbula.py</strong> Merimbula testing case</li>
</ul>
</li>
</ul>
</li>
<li><strong>OpenHMPP/</strong> Testing cases for OpenHMPP implementation

<ul>
<li><strong>merimbula.py</strong> Merimbula testing case</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Examples</h2>

<p>Running Merimbula model with CUDA implementation.</p>

<p><code>$ python merimbula.py -gpu</code></p>

<p>With pair-testing.</p>

<p><code>$ python merimbula.py -gpu -test</code></p>

<p>With rearranged mesh information.</p>

<p><code>$ python merimbula.py -gpu -rg</code></p>

<h2>Author</h2>

<p>Mail to <a href="wengcsyz@gmail.com">Zhe Weng (John)</a></p>
</body>
</html>